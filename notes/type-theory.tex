\chapter{Realizability and type theory}
\label{cha:type-theory-real}

In everyday mathematics \emph{parametrized} constructions are commonplace. For
example, when a mathematical text says ``consider a continuous map $f
: [a,b] \to \RR$'', there is an
implicit use of the parametrized set $[a,b] = \set{x \in \RR \such a
  \leq x \leq b}$, where $a$ and $b$ are the parameters. 
And whenever in algebra we say ``the cyclic group $\ZZ_n$'', that is not a single group, but a \emph{family} of groups parameterized by $n \in \NN$.

The language of such parameterized constructions is \defemph{(dependent) type theory}. It is applicable in many settings, including realizability. In this chapter we shall give an interpretation of type theory in terms of families of assemblies.


\section{Families of sets}
\label{sec:families-sets}

To set the scene, let us review the set-theoretic model of type theory. A \defemph{family of sets} is a map $A : I \to \Set$ from an \defemph{index set}~$I$ to the class of all sets. We say that \emph{$A$ is indexed by~$I$} or that it is \emph{a family over base~$I$}. Let $\Fam{I}$ be the class of all families indexed by~$I$.

Each $\Fam{I}$ is a category whose objects are the families indexed by~$I$. A morphism $f : A \to B$, where $A, B \in \Fam{I}$, is a \defemph{map of families} $f : A \to B$, which is a family of maps $f_i : A_i \to B_i$, parameterized by $i \in I$. Such maps are composed index-wise.

\begin{exercise}
  Recall the definition of the \defemph{slice category} $\Set/I$: an object is a map $a : A \to I$ with codomain~$I$, and a morphism a map $f : A \to B$ such that $b \circ f = a$:
  %
  \begin{equation*}
    \xymatrix@-1em{
      {A} \ar[rr]^{f}
      \ar[dr]_{a}
      & &
      {B}
      \ar[dl]^{b}
      \\
      & {I}
    }
  \end{equation*}
  %
  A map into~$I$ is called a \defemph{display map} over the \defemph{base~$I$}, and its domain the \defemph{total space}. (The terminology is inspired by a geometric picture of a bundle over a space.)

  For each $i \in I$ we define the \defemph{fiber} of~$a$ at~$i$ to be the inverse image $\invim{a} \set{i} = \set{x \in A \such a x = i}$. Thus a display map~$a$ over~$I$ yields an $I$-indexed family $i \mapsto \invim{a} \set{i}$ of fibers.
  %
  Conversely, a family $A : I \to \Set$ determines the display map, namely the first projection $\Sigma_I A \to I$.

  Verify that the passages between $\Fam{I}$ and $\Set/I$ constitute an equivalence of categories. As a first step you should determine how the equivalence acts on morphisms.
\end{exercise}

A map $r : J \to I$, induces \defemph{reindexing} $\invim{r} : \Fam{I} \to \Fam{J}$ by precomposition, $\invim{r} A = A \circ r$. Reindexing is contravariantly functorial,
%
\begin{equation*}
  \invim{\id[I]} A  = A
  \qquad\text{and}\qquad
  \invim{(s \circ r)} A = \invim{r} (\invim{s} A).
\end{equation*}
%
Therefore, families and reindexings form a functor $\opcat{\Set} \to \Cat$.

\subsection{Products and sums of families of sets}
\label{sec:prod-sums-sets}

The two fundamental operations on families of sets are the cartesian products and sums. 
Given a family $A \in \Fam{I}$, its \defemph{product} $\Pi_I A$ and \defemph{sum} $\Sigma_I A$ are respectively the sets
%
\begin{align*}
  \Pi_I A &= 
  \textstyle
  \set{ u : I \to \bigcup_{i \in I} A_i \such \all{i \in I} u i \in A_i }, \\
  \Sigma_I A &= \set{ (i, a) \such i \in I \land a \in A_i }.
\end{align*}
%
The elements of the product are called \defemph{choice maps}.

We shall need their generalized forms, where the product and the sum is taken with respect to a reindexing, as follows.
%
Consider $r : J \to I$ and $A \in \Fam{J}$. For $K \subseteq I$ write\sidenote{Careful, the notation $\invim{r}$ is used both for $\invim{r} : \pow{I} \to \pow{J}$ and $\invim{r} : \Fam{I} \to \Fam{J}$. The coincidence is not accidental.} $\invim{r} K = \set{ j \in J \such r j \in K}$, and define the \defemph{product} $\Pi_r A \in \Fam{I}$ and the \defemph{sum} $\Sigma_r A \in \Fam{I}$ by
%
\begin{align}
  \label{eq:pi-r}
  (\Pi_r A)_i &=
    \set{ u : \invim{r} \set{i} \to \textstyle\bigcup_{j \in \invim{r} \set{i}} A_j
            \such \all{j \in \invim{r} \set{i}} u j \in A_j
    }
  \\
  \notag
  (\Sigma_J A)_i &= \set{ (j, x) \such j \in \invim{r} \set{i} \land x \in A_j }.
\end{align}
%

\begin{exercise}
  Show that $\Pi_r : \Fam{J} \to \Fam{I}$ is a functor by providing a suitable action on the morphisms, and similarly for $\Sigma_r$.
\end{exercise}





The distinguishing feature of products and sums is that they are adjoint to reindexing,
%
\begin{equation*}
  \Sigma_r \dashv \invim{r} \dashv \Pi_r.
\end{equation*}
%
Concretely, the above amounts to having isomorphisms, natural in $A \in \Fam{J}$ and $B \in \Fam{I}$,
%
\begin{equation*}
  \Hom[\Fam{I}]{\Sigma_r A, B}
  \cong
  \Hom[\Fam{J}]{A, \invim{r} B}
\end{equation*}
%
and
%
\begin{equation*}
  \Hom[\Fam{I}]{B, \Pi_r A}
  \cong
  \Hom[\Fam{J}]{\invim{r} B, A}.
\end{equation*}
%
We spell out the second isomorphism and leave the first one as an exercise.
%
Given a map of families $f : B \to \Pi_r A$, define $\hat{f} : \invim{r} B \to A$ by
%
\begin{equation}
  \label{eq:sub-adj-pi-hat}
  \hat{f}_j x = f_{r j} x j,
\end{equation}
%
and given $g : \invim{r} B \to A$ define $\check{g} : B \to \Pi_r A$ by 
%
\begin{equation}
  \label{eq:sub-adj-pi-check}
  \check{g}_i x j = g_j x.
\end{equation}
%
It is easy to see that $f \mapsto \hat{f}$ and $g \mapsto \check{g}$ are inverses of each other. Checking naturality is less pleasant but instructive.

\begin{exercise}
  Complete the verification of $\Sigma_r \dashv \invim{r} \dashv \Pi_r$.
\end{exercise}

\subsection{Type theory as the internal language}
\label{sec:interpr-type-theory}

Having identified the relevant set-theoretic structure, we can now interpret the language of type theory in set theory.

\subsubsection{Contexts}
\label{sec:contexts}

In type theory the index sets are called \defemph{contexts}. In practice they are not arbitrary sets (although they can be), but are rather built up by introduction of new parameters in an inductive fashion:
%
\begin{itemize}
\item the empty context is the singleton\sidenote{A family of sets which does not depend on any parameters is just a fixed set, so an element of $\Fam{\one}$. If you think the empty context should be $\emptyset$, consider what $\Fam{\emptyset}$ is like.} $\emptyCtx = \set{\star}$,
\item given a context $\Gamma$ and a family of sets $A \in \Fam{\Gamma}$, the \defemph{extended context} is the sum $\Sigma_\Gamma A$.
\end{itemize}

By iterating context extension we obtain a \defemph{telescope}
%
\begin{equation*}
  \Sigma_{\Sigma_{\cdots \Sigma_{\Sigma_{\emptyCtx} \cdots} A_{n-2}} A_{n-1}} A_n.
\end{equation*}
%
Such a nested sum is unwieldy, so we write it as
%
\begin{equation*}
  x_1 \of A_1, x_2 \of A_2, \ldots, x_n \of A_n.
\end{equation*}
%
where $x_1, \ldots, x_n$ are distinct variable names. This way we may access the components of the telescope by referring to the variables, rather than having to use iterated projections.
%
The elements of a telescope are tuples\sidenote{To be quite precise, the elements are nested pairs $(((\star, a_1), a_2) \cdots, a_n)$ but we might as well use these as the definition of $n$-tuples $(a_1, \ldots, a_n)$.} $(a_1, \ldots, a_n)$ such that $a_i \in A_{(a_1, \ldots, a_{i-1})}$ for $i = 1, \ldots, n$.
%
Once again, ``context'' is a synonym for ``set'', but in practice we use telescopes.

\begin{example}
  \label{example:context}
  %
  Suppose a mathematical text says
  %
  \begin{quote}
    \emph{``Consider a continuous $f : [a, b] \to \RR$ bounded by $M \in \RR$.''}
  \end{quote}
  %
  What precisely is the context? It is implied that $a, b \in \RR$, so at first we might think that the context is
  %
  \begin{equation*}
    a \of \RR, \quad
    b \of \RR, \quad
    f \of [a, b] \to \RR, \quad
    M \of \RR.
  \end{equation*}
  %
  However, there are also three \emph{hypotheses}, namely that $a < b$, that $f$ is continuous, and that~$f$ is bounded by~$M$.
  %
  Mathematical tradition would have us ignore these, because it demands that proofs and logical statements be considered second-class. Indeed, notice how the text introduces names $a, b, f, M$ for all the entities \emph{except} the hypotheses, and even these notes refer to theorems by mere unmemorable numbers, as if it were forbidden to name them.
  %
  The correct context is, written vertically for readability,
  %
  \begin{align*}
    & a : \RR, \\
    & b : \RR, \\
    & p : (a < b), \\
    & f : [a, b] \to \RR, \\
    & q : \mathsf{continuous}(f), \\
    & M : \RR, \\
    & r : \all{x \in [a,b]} f(x) \leq M
  \end{align*}
  %
  However, we now face a difficulty: in what sense are logical formulas, such as $a < b$ and $\mathsf{continuous(f)}$ families of sets? They must be, if they are to appear in contexts. We shall resolve the matter in \cref{{sec:prop-trunc}}.
\end{example}

\subsubsection{Type families and their elements}
\label{sec:type-families}

When type theory is used to talk about set theory, we prefer to say \defemph{type} and \defemph{type family} instead of ``set'' and ``set family'', and write
%
\begin{equation*}
  \Gamma \types A \istype
\end{equation*}
%
for $A \in \Fam{\Gamma}$.
%
The \defemph{elements} of~$A$ are its choice maps. We write
%
\begin{equation*}
  \Gamma \types t : A
\end{equation*}
%
when $t$ is such a choice map.

\begin{example}
  To see why it makes sense to call the choice maps ``elements'',
  we translate the statement
  %
  \begin{quote}
    \emph{``$(a + b)/2$ is an element of the closed interval $[a,b]$.''}
  \end{quote}
  %
  to the type-theoretic terminology. First, the text expects us to guess that~$a$ and~$b$ are reals such that $a < b$, so the context is
  %
  \begin{equation*}
    a \of \RR,\quad b \of \RR,\quad p \of (a < b).
  \end{equation*}
  %
  Over this context we define a type family~$C$ of closed intervals by\sidenote{Dragging along the argument~$p$ seems a little bureaucratic. In practice we would of course drop it, and in a proof assistant we might use one of several mechanisms that hide it.}
  %
  \begin{equation*}
    C_{(a, b, p)} = [a, b] = \set{x \in \RR \such a \leq x \leq b}.
  \end{equation*}
  %
  The mid-point is map~$m$ which assigns to each interval its mid-point, $m(a, b, p) = (a + b)/2$, which of course is just a choice map for~$C$.
\end{example}

\subsubsection{Dependent products and sums}
\label{sec:depend-sums-prod-in-sets}

If a family is indexed by a telescope with parameters $x_1, \ldots, x_n$, we may wish to form the cartesian product with respect to just~$x_n$,
which is accomplished by taking the product~\eqref{eq:pi-r} along a suitable reindexing.
%
Suppose $\Gamma, x \of A \types B \istype$ and let $p : (\Gamma, x \of A) \to \Gamma$ be the first projection $p(\gamma, a) = \gamma$.
%
Define the \defemph{product} of~$B$ to be the type family $\Gamma \types \Pi_p B \istype$.
Unfolding the definitions shows that, for $\gamma \in \Gamma$,
%
\begin{align*}
  (\Pi_p B)_\gamma &=
  \set{ u : \invim{p} \set{\gamma} \to
        \textstyle\bigcup_{\delta \in \invim{p} \set{\gamma}} B_\delta
    \such \all{\delta \in \invim{p} \set{\gamma}} u \delta \in B_\delta
  } \\
  &\cong
  \set{ u : A_\gamma \to
        \textstyle\bigcup_{a \in A_\gamma} B_{(\gamma, a)}
    \such \all{a \in A_\gamma} u a \in B_{(\gamma, a)}
  },
\end{align*}
%
which is precisely the desired parameterized version of cartesian product.

A similar line of though show that the \defemph{sum} of a family $\Gamma, x \of A \types B \istype$ is the family $\Gamma \types \Sigma_p B$, where $p$ is as above. It is the parameterized version of the disjoint sum, or coproduct, of a family:
%
\begin{align*}
  (\Sigma_p B)_\gamma &=
  \set{ (\delta, b) \such \delta \in \invim{\gamma} \set{\gamma} \land b \in B_\delta }
  \\
  &\cong
  \set{ (a, b) \such a \in A_\gamma \land b \in B_{(\gamma, a)}}.
\end{align*}

\begin{exercise}
  Explicitly write down the isomorphisms appearing in the above calculations
  of $\Pi_p B$ and $\Sigma_p B$. Does it matter which of the two isomorphic versions of products and sums we use?
\end{exercise}

\section{Families of assemblies}
\label{sec:families-assemblies}

The interpretation of type theory in assemblies proceeds much as in sets, we only need to make sure that the set-theoretic maps are realized. However, we must first define what a family of assemblies is.

Defining a family of assemblies to be a collection of assemblies indexed by (the underlying set of) an assembly almost works, we just have to additionally require that all the assemblies in the family share the same underlying type.\sidenote{This is so because tpcas are simply typed. By making all the assemblies in the family share the same type, we facilitate the construction of its product, whose underlying type may then be the (non-dependent) function type, see \cref{sec:depend-sums-prod}.}

\begin{definition}
  A \defemph{(uniform) family of assemblies} $S : I \to \AsmA$ is given by an
  \defemph{index assembly~$I$}, an \defemph{underlying type} $\T{S}$, and for each
  $i \in \S{I}$ an assembly $S_i$ such that $\T{S_i} = \T{S}$.
\end{definition}

The qualifier ``uniform'' refers to the fact that all the members share the same underlying type. We drop it because we only ever consider uniform families.
%
We write $\Fam[\AA, \subAA]{I}$ or just $\Fam{I}$ for the collection of all families of assemblies indexed by~$I$. For everything to work out, maps between families of assemblies have to be uniformly realized.

\begin{definition}
  A \defemph{(uniform) map of families} $f : A \to B$ between families of assemblies $A, B \in \Fam{I}$ is given by a family of maps $(f_i : \S{A_i} \to \S{B_i})_{i \in \S{I}}$
  for which there exists $\R{f} \in \subAtyp{\S{I} \to \S{A} \to \S{B}}$ such that,
  for all $i$, $\R{i}$, $x$, $\R{x}$,
  %
  \begin{equation*}
    \R{i} \rz[I] i \land \R{x} \rz[A_i] x \implies \R{f}\,\R{i}\,\R{x} \rz[B_i] f x.
  \end{equation*}
\end{definition}

The definition endows each $\Fam{I}$ with the structure of a category.
%
An assembly map $r : J \to I$ induces a \defemph{reindexing} $\invim{r} : \Fam{I} \to \Fam{J}$, defined by
%
\begin{equation*}
  \invim{r} A = A \circ r.
\end{equation*}
%
There is nothing here to be realized, but we shall use realizers for~$r$ in the construction of products and sums.

\begin{exercise}
  Verify that reindexing is contravariantly functorial.
\end{exercise}


\subsection{Products and sums of families of assemblies}
\label{sec:depend-sums-prod-asm}

Consider a family of assemblies $S \in \Fam{J}$. It has an associated family of underling sets $\S{S} \in \Fam{J}$, defined by $j \mapsto \S{S_j}$. Given an assembly map $r : J \to I$, $i \in \S{I}$, and $u \in (\Pi_r \S{S})_i$, say that $u$ is \defemph{realized} by $\R{u} \in \Atyp{\T{J} \to \T{S}}$ when, for all $j \in \invim{r} \set{i}$ and $\R{j} \in \Atyp{\T{J}}$,
%
\begin{equation*}
  \R{j} \rz[J] j \implies
  \R{u}\,\R{j} \rz[S_i] u j.
\end{equation*}
%
When this is the case, we write $\R{u} \rz[(\Pi_r S)_i] u$.
%
Now define the \defemph{product} $\Pi_r S \in \Fam{I}$ to be the family whose realizability relation at $i \in \S{I}$ is~$\rz[(\Pi_r S) i]$ and
%
\begin{align*}
  \T{\Pi_r S} &= \T{J} \to \T{S}, \\
  \S{(\Pi_r S)_i} &= 
    \set{ u \in (\Pi_r \S{S})_i \such
       \some{\R{u} \in \Atyp{\T{J} \to \T{S}}} \R{u} \rz[(\Pi_r S)_i] u
    }.
\end{align*}
%
Define the \defemph{sum} $\Sigma_r S \in \Fam{J}$ to be the family
%
\begin{align*}
  \T{\Sigma_r S} &= \T{J} \times \T{S}, \\
  \S{(\Sigma_r S)_i} &= (\Sigma_r \S{S})_i, \\
  \R{r} \rz[(\Sigma_r S)_i] (j, x) &\liff
  \combFst\,\R{r} \rz[J] j \land \combSnd\,\R{r} \rz[S_j] x.
\end{align*}
%
Notice how at the level of underlying types the dependency on the
parameter disappears because we required the families to be
uniform.

\begin{exercise}
  Verify the adjunctions
  %
  \begin{equation*}
    \Sigma_r \dashv \invim{r} \dashv \Pi_r.
  \end{equation*}
  %
  Half of work has been done in \cref{sec:prod-sums-sets}.
  You still need to check that the map of families $\hat{f}$ defined in~\eqref{eq:sub-adj-pi-hat} is realized when~$f$ is realized, and similarly for $\check{g}$ defined in~\eqref{eq:sub-adj-pi-check}.
\end{exercise}

Products and sums along arbitrary reindexings are perhaps a bit unintuitive. For better understanding we spell out the non-parameterize sum and products.
%
Given a family $S \in \Fam{I}$, its \defemph{product} $\Pi_I S$ is the assembly
%
\begin{align*}
  \T{\Pi_I S} &= \T{I} \to \T{S}, \\
  \S{\Pi_I S} &= \textstyle
     \set{u \in \Pi_{\S{I}} \S{S} \such
          \some{\R{u} \in \Atyp{\T{I} \to \T{S}}} \R{u} \rz[\Pi_I S] u
     },\\
  \R{u} \rz[\Pi_I S] u &\liff
  \all{i \in \S{I}, \R{i} \in \Atyp{\T{I}}}
    \R{i} \rz[I] i \lthen \R{u}\,\R{i} \rz[S_i] u i.
\end{align*}
%
The \defemph{sum} $\Sigma_I S$ is the assembly
%
\begin{align*}
  \T{\Sigma_I S} &= \T{I} \times \T{S}, \\
  \S{\Sigma_I S} &= \Sigma_{\S{I}} \S{S}, \\
  \R{r} \rz[\Sigma_I S] (i, x) &\liff
    \combFst\,\R{r} \rz[I] i \land
    \combSnd\,\R{r} \rz[S_i] x.
\end{align*}
%
These are indeed just the familiar set-theoretic constructions embellished with realizers.

\subsection{Contexts of assemblies}
\label{sec:contexts-assemblies}

Contexts of assemblies are built as iterated sums, the same was as contexts of sets.
Thus a telescope of assemblies
%
\begin{equation*}
  \Gamma = (x_1 : S_1, \ldots, x_n : S_n)
\end{equation*}
%
is the assembly
%
\begin{align*}
  \T{\Gamma} &= \T{S_1} \times \cdots \times \T{S_n}, \\
  \S{\Gamma} &= \set{(a_1, \ldots, a_n) \such \all{i \leq n} a_i \in \S{(S_i)_{(a_1, \ldots, a_{i-1})}}} \\
  \R{r} \rz[\Gamma] (a_1, \ldots, a_n)
  &\liff
  \all{i \leq n} \pcacomb{proj}_{n,i}\,\R{r} \rz[(S_i)_{(a_1, \ldots, a_{i-1})}] a_i,
\end{align*}
%
where $\pcacomb{proj}_{n,i}$ is the $i$-th projection from an $n$-tuple.

\section{Propositions as assemblies}
\label{sec:prop-as-assemblies}

In \cref{example:context} we placed a hypothesis into the context, but for this to make sense in needs to be a type family. How can a proposition be a type?

In classical logic a predicate $\phi$ on a set~$A$ is a Boolean function $\phi : S \to \{\bot, \top\}$. If we encode the truth values $\bot$ and $\top$ with sets, $\phi$ becomes a family of sets, which is what we want. A choice that works well is to take~$\bot$ to be~$\emptyset$ and~$\top$ to be~$\set{\star}$. An even better idea is to allow any singleton set to represent truth, they are all isomorphic anyhow. We may do the same with assemblies.

\begin{definition}
  An assembly is a \defemph{proposition} if all of its elements are equal.\sidenote{Even though ``all elements are equal'' is equivalent to ``empty or singleton'', the choice of wording matters once we bring in realizability logic, where excluded middle is not valid.}
  %
  A \defemph{predicate} on an assembly~$S$ is a family of assemblies $P \in \Fam{S}$ such that $P x$ is a predicate for all $x \in \S{S}$.
\end{definition}

To see that the definition works, note that the following logical operations can be expressed with standard constructions on assemblies:
%
\begin{equation}
  \label{eq:prop-as-type-negative}
  \begin{aligned}
    \bot &\;=\; \Zero, \\
    \top &\;=\; \One, \\
    P \land Q &\;=\; P \times Q, \\
    P \lthen Q &\;=\; P \to Q,, \\
    \forall_S R &\;=\; \Pi_S R.
  \end{aligned}
\end{equation}
%
For instance, $P \times Q$ is inhabited if, and only if, both~$P$ and~$Q$ are, which is precisely how conjunction is supposed to be.
%
Similarly, the product $\Pi_S R$ has a choice map only if\sidenote{We did \emph{not} say ``if and only if'' because in assemblies choice maps must also be realized. It is quite possible that there is no realized choice map for a family of assemblies, even though every one of its member is inhabited. Even so, $\Pi_S R$ satisfies the rules of universal quantification, and so can be used as such.} all the assemblies $R x$ are inhabited, which again characterizes the universal quantifier.

Disjunction and the existential quantifier present a bit of a challenge. How about
%
\begin{equation*}
  P \lor Q \;=\; P + Q
  \qquad\text{and}\qquad
  \exists_S R \;=\; \Sigma_S R \ ?
\end{equation*}
%
The definitions seem to work: $P + Q$ is inhabited if, and only if, $P$ or $Q$ is inhabited; and $\Sigma_S R$ is inhabited if, and only if, there is $x \in \S{S}$ for which $P x$ has an element.\sidenote{We are a bit sloppy with these statements because we should also think about realizers.} The problem is that $P + Q$ and $\Sigma_S R$ need not be propositions because they may have more than one element. There are two ways to fix the deficiency.

Firstly, we can force any assembly $P$ to become a proposition $\Trunc{P}$ by quotienting it with respect to the trivial equivalence relation. Disjunction and existential quantification are then defined as
%
\begin{equation}
  \label{eq:trunc-or-exists}
  \begin{aligned}
    P \lor Q &\;=\; \Trunc{P \lor Q}, \\
    \exists_S R &\;=\; \Trunc{\Sigma_S R}.
  \end{aligned}
\end{equation}
%
This option is explored in \cref{sec:prop-trunc-asm}.

Secondly, why do we insist that propositions must have at most one element? We could use \emph{all} assemblies as if they were propositions, with the empty assembly representing falsehood and the inhabited assemblies truth. The correspondence~\eqref{eq:prop-as-type-negative} still holds and can even be extended to
%
\begin{align*}
  P \lor Q &\;=\; P + Q, \\
  \exists_S R &\;=\; \Sigma_S R.
\end{align*}
%
This approach is taken in Martin-Löf type theory and goes by the name \defemph{propositions as types}.

Which definition of $\lor$ and $\exists$ should we adopt? Mathematical practice uses both. The truncated sum $\Trunc{\Sigma_S R}$ is a form of \emph{abstract existence} because its element, when it exists, reveals no specific $x \in \S{S}$ for which $R x$ is inhabited; whereas $\Sigma_S R$ is \emph{concrete existence} because its elements provide witnesses. Similarly, $\Trunc{P + Q}$ states that one or the other disjunct holds without revealing which one, whereas an element of $P + Q$ makes a specific choice of one or the other.

Judicious use of propositional truncation thus makes it possible to formalize aspects of mathematical practice that are not easily incorporated into traditional first-order logic, which provides only abstract existence and disjunction, nor into traditional Martin-Löf type theory, which provides only concrete existence and disjunction.

\subsection{Propositional truncation of an assembly}
\label{sec:prop-trunc-asm}

Propositional truncation works both for sets and assemblies. The propositional truncation $\Trunc{A}$ of a set $A$ is the quotient $A/{\sim}$ by the full relation~$\sim$ on~$A$.
%
The quotient map takes an element $x \in A$ to its equivalence class $\trunc{x} = A$.
%
Thus, if $A$ has an element then $\Trunc{A} = \set{A}$ and if $A$ is empty then $\Trunc{A} = \emptyset$.
%
A category theorist would postulate $\Trunc{A}$ as the coequalizer
%
\begin{equation*}
  \xymatrix{
    {A \times A}
    \ar@<0.5ex>[r]^{\pi_1}
    \ar@<-0.5ex>[r]_{\pi_2}
    &
    {A}
    \ar@{->>}[r]^{\trunc{{-}}}
    &
    {\Trunc{A}}
  }
\end{equation*}
%
This construction works in categories other than sets. It takes an assembly $S$ to its \defemph{propositional truncation} $\Trunc{S}$ where\sidenote{It is too late to disentangle the conflicting notations for propositional truncation and the underlying type. We could insert parentheses,
$\T{(\Trunc{S})} = \T{S}$
and
$\S{(\Trunc{S})} = \Trunc{(\S{S})}$, but that just ruins the fun.}
%
\begin{align*}
  \T{\Trunc{S}} &= \T{S}, \\
  \S{\Trunc{S}} &= \Trunc{\S{S}}, \\
  \R{r} \rz[\Trunc{S}] \xi
  &\liff
    \some{y \in \S{S}} \R{r} \rz[S] y.
\end{align*}
%
Like any worthy construction, propositional truncation has a universal property stemming from the above coequalizer diagram: if $P$ is a proposition then for every assembly map $f : S \to P$ there is a unique $\bar{f} : \Trunc{S} \to P$ such that the following diagram commutes:
%
\begin{equation*}
  \xymatrix{
    {S}
    \ar[r]^{\trunc{{-}}}
    \ar[rd]_{f}
    &
    {\Trunc{S}}
    \ar[d]^{\bar{f}}
    \\
    &
    {P}
  }
\end{equation*}

\begin{exercise}
  Verify that the universal property of propositional truncation holds with respect to families of assemblies. Given a family of assemblies $S \in \Fam{\Gamma}$, a predicate $P \in \Fam{\Gamma}$ and a map of families $f : S \to P$, there is a unique map of families $\bar{f} : \Trunc{S} \to P$ such that $\bar{f} \circ \trunc{{-}} = f$.

  Moreover, explain what it means for propositional truncation to be functorial with respect to reindexing, then show that it is.
\end{exercise}


\subsection{Realizability predicates and propositions}
\label{sec:real-pred-prop}

In \cref{cha:realizability-logic} we gave a realizability interpretation of logic, with its own notions of propositions and predicates. We show that it is equivalent to truncated logic of the present chapter.

Let $\PredT{S}$ be the class of predicates on~$S$ in the sense of the present chapter, i.e., families of assemblies $P \in \Fam{S}$ such that $\all{u, v \in \S{P x}} u = v$ for all $x \in \S{S}$. We endow $\PredT{S}$ with a preorder $\entails'$, defined by
%
\begin{equation*}
  P \entails' Q \iff
  \text{there is a map of families $P \to Q$}.
\end{equation*}
%
In fact, there is at most one map of families $P \to Q$.

\begin{exercise}
  Verify that the preoder $\PredT{S}$ forms a Heyting prealgebra with the operations given by~\eqref{eq:prop-as-type-negative} and~\eqref{eq:trunc-or-exists}.
\end{exercise}


\begin{theorem}
  \label{thm:pred-equiv-pred}
  The Heyting prealgebras $(\Pred{S}, {\entails})$ and $(\PredT{S}, {\entails'})$ are equivalent.
\end{theorem}

\begin{proof}
  The equivalence takes a realizability predicate $p \in \Pred{S}$ to the family
  $P_p \in \Fam{S}$, defined by
  %
  \begin{align*}
    \T{P_p} &= \T{p}, \\
    \S{P_p x} &= \one, \\
    \R{r} \rz[P_p x] \star &\liff \R{r} \rz p x.
  \end{align*}
  %
  In the opposite direction, a predicate $P \in \PredT{S}$ is taken to the realizability predicate $p_P \in \Pred{S}$, defined by
  %
  \begin{align*}
    \T{p_P} = \T{P}, \\
    \R{r} \rz p_P x &\liff \some{\xi \in P x} \R{r} \rz[P x] \xi.
  \end{align*}
  %
  To finish the proof, one would have to verify that $p \to P_p$ and $P \to p_P$ are monotone, that $p \bientails p_{P_p}$ and $P \bientails' P_{p_P}$, and that they preserve the Heyting prealgebra structure.
\end{proof}

\begin{exercise}
  In the proof of \cref{thm:pred-equiv-pred} the passage from $P$ to realizability predicate $p_P$ works for an arbitrary family~$P \in \Fam{S}$. Therefore, the equivalence extends to a pair of functors
  %
  \begin{equation*}
    \xymatrix{
      {\Pred{S}}
      \ar@<0.5ex>[r]^{I}
      &
      {\Fam{S}}
      \ar@<0.5ex>[l]^{T}
    }
  \end{equation*}
  %
  Show that $I$ is full and faithful, $T$ is its left adjoint, and that $I \circ T$ is naturally isomorphic to propositional truncation. How does the adjunction interact with reindexing?
\end{exercise}

The realizability logic in \cref{cha:realizability-logic} gave the simple definition of quantifiers where one of the parameters of a two-parameter predicate was quantified over. We can improve on that by defining quantification with respect to reindexing.

An assembly map $r : J \to I$ induces a monotone map $\invim{r} : \Pred{J} \to \Pred{I}$ which acts by precomposition, $\invim{r} p = p \circ r$. The \defemph{universal quantification} of $p \in \Pred{J}$ \defemph{along~$r$} is the realizability predicate $\forall_r p \in \Pred{I}$, defined by
%
\begin{align*}
  \T{\forall_r p} &= \T{J} \to \T{p}, \\
  \R{u} \rz (\forall_r p) i &\liff
    \all{j \in \invim{r} \set{i}}
    \all{\R{j} \in \T{J}}
    \R{j} \rz[J] j \lthen \R{u}\,\R{j} \rz p j.
\end{align*}
%
Define the \defemph{existential quantification along~$r$} to be the realizability predicate $\exists_r p \in \Pred{I}$,
%
\begin{align*}
  \T{\exists_r p} &= \T{J} \times \T{p}, \\
  \R{r} \rz (\exists_r p) i &\liff
  \some{j \in \S{J}}
   \combFst\,\R{r} \rz[J] j
   \land
   \combSnd\,\R{r} \rz p j.
\end{align*}
%
The quantifiers from \cref{sec:quantifiers} arise as quantification along a projection $T \times S \to S$.

\begin{exercise}
  Verify that the equivalence of $\Pred{S}$ and $\PredT{s}$ preserves the quantifiers as well.
\end{exercise}

Henceforth we shall use one or the other formulation of realizability predicates, whichever is more appropriate in the situation at hand.


\section{Identity types}
\label{sec:identity-types}

In \cref{sec:equality} we defined equality on an assembly~$S$ as as predicate on $S \times S$. The corresponding family of assemblies $\Id[S] \in \Fam{S \times S}$ is given by
%
\begin{equation*}
  \T{\Id[S]} = \unit
  %
  \qquad\text{and}\qquad
  %
  \Id[S](x, y) =
  \begin{cases}
    \One & \text{if $x = y$,} \\
    \Zero & \text{if $x \neq y$.}
  \end{cases}
\end{equation*}
%
It is called the \defemph{identity type} of~$S$.

If we compose~$\Id[S]$ with the diagonal map $S \to S \times S$ we get the family $x \mapsto \Id[S](x,x)$ which has an element $\refl[S]$, namely $\refl[S](x) = \star$, realized by $\tpcalam{x}{\T{S}}{\ttunit}$.

The identity type in Martin-Löf type theory satisfies the following elimination principle. Suppose $\Gamma$ is a context and $\Gamma \types S \istype$ a type over it.




\subsection{UIP and equality reflection}
\label{sec:uip-equal-refl}

\section{Inductive and coinductive types}
\label{sec:inductive-counductive-types}

\section{Universes}
\label{sec:universes}

\subsection{Universes of propositions}
\label{sec:universe-propositions}

The universe of decidable propositions.

The universe of semi-decidable propositions.

The universe of stable propositions.

The universe of propositions.

\subsection{The universe of modest sets}
\label{sec:universe-modest-sets}

\subsection{The universe of small assemblies}
\label{sec:univ-small-assembl}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "notes-on-realizability"
%%% End:
