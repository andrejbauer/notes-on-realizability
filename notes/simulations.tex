\section{Simulations}
\label{sec:simulations}%

If you open a book on computability theory, chances are that you will find a statement saying that ``models of computation are equivalent''. The claim refers to a collection of specific models of computation, such as variations of Turing machines, $\lambda$-calculi, and recursive functions. The book supports the claim by describing simulations between such models, with varying degrees of detail, after which it hurries on to core topics of computability theory. An opportunity is missed to ask about a general notion of simulation, and a study of its structural properties.


We seize the opportunity and study a notion of simulation between pcas. An excellent one is John Longley's \emph{applicative morphism}~\sidecite{Longley:94}. His definition extends easily to account for pcas with sub-pcas. We dare rename applicative morphisms to \emph{simulations}, and consider only the untyped simulations. The typed version of simulations can also be set up as well, see~\sidecite{longley99:_match}.

\begin{definition}
  \label{def:simulation}%
  %
  \indexsee{morphism!applicative}{applicative, morphism}%
  \indexdef{applicative!morphism}%
  \indexdef{simulation}%
  %
  A \defemph{(pca) simulation}, originally called an \defemph{applicative morphism}~\cite{Longley:94},
  $\rho: \EE \pcato \FF$ between pcas~$\EE$ and~$\FF$ is a total relation $\rho
  \subseteq \EE \times \FF$ for which there exists a \defemph{realizer} $r \in \FF$
  %
  \indexdef{realizer!for applicative morphism}%
  \indexdef{applicative!morphism!realizer for}%
  \indexdef{realizer!for simulation}%
  \indexdef{simulation!realizer for}%
  %
  such that, for all $u, v \in \EE$ and $x, y \in \FF$,
  %
  \begin{itemize}
  \item if $\rho(u, x)$ then $\defined{r \, x}$ and
  \item if $\rho(u, x)$, $\rho(u, y)$ and $\defined{u \, v}$ then
    $\defined{r \, x \, y}$ and $\rho(u \, v, r \, x \, y)$.
  \end{itemize}
  %
  We write $\rho[u] = \set{x \in \FF \such \rho(u, x)}$.

  A \defemph{(sub-pca) simulation} $\rho: (\EE, \subEE) \pcato (\FF, \subFF)$ between pcas with sub-pcas is a simulation
  $\rho : \EE \pcato \FF$ which has a realizer $r \in \subFF$, and such that $\rho$ restricted to $\subEE \times \subFF$ is a simulation $\subEE \pcato \subFF$ realized by~$r$.
\end{definition}

A realizer $r \in \FF$ of a simulation is of course precisely an implementation in~$\FF$ of the applicative structure of~$\EE$.

We defined a simulation to be a total relation rather than a function because an element of the domain may be simulated by many elements of the codomain, without any one being preferred or distinguished. The notation $\rho[u]$ 
suggests that~$\rho$ is construed as a multi-valued map rather than a relation.

One might expect that a simulation ought to be a map $f : \EE \to \FF$ such that $f(\combK_\EE) = \combK_\FF$, $f(\combS_\FF) = \combS_\FF$, and $f (x \cdot_\EE y) \kleq f x \cdot_\FF f y$. This is how an algebraist would define a morphism, but we are interested in the computational aspects of pcas, not the algebraic ones.

\index{simulation!composition of}%
\index{composition!simulations}%
%
Simulations can be \defemph{composed} as relations.
If $\rho: (\EE, \subEE) \pcato (\FF, \subFF)$ and $\sigma: (\FF,
\subFF) \pcato (\GG, \subGG)$ then $\sigma \circ \rho: (\EE, \subEE)
\pcato (\GG, \subGG)$ is defined, for $x \in \EE$ and $z \in \GG$, by
%
\begin{equation*}
  z \in (\sigma \circ \rho)[x]
  \iff
  \some{y \in \FF} y \in \rho[x] \land z \in \sigma[y].
\end{equation*}

\begin{exercise}
  Show that $\sigma \circ \rho$ is realized if $\rho$ and $\sigma$ are.
\end{exercise}

The identity simulation $\id[(\EE, \subEE)]: (\EE,
\subEE) \pcato (\EE, \subEE)$ is the identity relation on~$\EE$. It is realized by $\pcalam{x\,y} x \, y$.

Pcas with sub-pcas and simulations between them therefore form a category. We equip it with a \defemph{preorder enrichment}\sidenote{A category $\mathcal{C}$ is preorder enriched when hom-sets $\mathcal{C}(X,Y)$ are equipped with preorders (reflexive and transitive relations) under which composition is monotone.} $\preceq$ as follows.
%
\indexdef{category!of simulations}%
\index{translation, of simulations}%
\index{equivalence!of pcas}%
%
Given $\rho, \sigma : (\EE, \subEE) \pcato (\FF, \subFF)$, define $\rho \preceq \sigma$ to hold when
there exists a \defemph{translation} $t \in \subFF$ such that, for all $x \in \EE$ and $y \in \rho[x]$, $\defined{t \, y}$ and $t \, y \in \sigma[x]$.

We write $\rho \sim \sigma$ when $\rho \preceq \sigma$ and $\sigma \preceq \rho$.

\begin{exercise}
  Given $\rho, \rho' : (\EE, \subEE) \pcato (\FF, \subFF)$ and $\sigma, \sigma' : (\FF, \subFF) \pcato (\GG, \subGG)$, show that if $\rho \preceq \rho'$ and $\sigma \preceq \sigma'$ then $\sigma \circ \rho \preceq \sigma' \circ \rho'$.
\end{exercise}

The preorder enrichment induces the notions of equivalence and adjunction of simulations.

\goodbreak

\begin{definition}%
  %
  \index{simulation!adjoint pair of}%
  \index{adjunction!simulation}%
  %
  Consider simulations
  %
  \begin{align*}
    \delta &: (\EE, \subEE) \pcato (\FF, \subFF),
    &
    \gamma &: (\FF, \subFF) \pcato (\EE, \subEE).
  \end{align*}
  %
  They form an \defemph{equivalence} when $\gamma \circ \delta \sim \one_\EE$ and $\delta \circ \gamma \sim \one_\FF$.

  They form an \defemph{adjunction}, written $\gamma \dashv \delta$, when
  %
  $\one_{\FF} \preceq \delta \circ \gamma$ and $\gamma \circ
  \delta \preceq \one_{\EE}$. We say that~$\gamma$ is \defemph{left
    adjoint} to~$\delta$, or that~$\delta$ is \defemph{right adjoint}
  to~$\gamma$.

  \indexdef{simulation!adjoint inclusion}%
  \indexdef{simulation!adjoint retraction}%
  \indexsee{adjoint inclusion!simulation}{simulation, inclusion}%
  \indexsee{adjoint retraction!simulation}{simulation, retraction}%
  %
  Such an adjoint pair is an \defemph{adjoint inclusion} when $\gamma \circ \delta \sim \id[\EE]$, and a
  \defemph{adjoint retraction} when $\delta \circ \gamma \sim \one_\FF$.
\end{definition}

\subsection{Properties of simulations}
\label{sec:prop-simul}

Nothing prevents a simulation from being trivial. In fact, there always is the constant simulation $\tau : \EE \pcato \FF$, defined by $\tau[x] = \set{\combK_{\FF}}$ and realized by $\pcalam{x\,y} \combK$. To avoid such examples, we should identify further useful properties of simulations.

Discreteness prevents a simulation from conflating simulated elements.

\begin{definition}
  A simulation $\rho: (\EE, \subEE) \pcato (\FF, \subFF)$ is
  %
  \indexdef{simulation!discrete}%
  \indexdef{discrete!simulation}%
  %
  \defemph{discrete} when, for all $x, y \in \EE$ if $\rho[x] \cap \rho[y]$ is in inhabited then $x = y$.
\end{definition}

The next property is single-valuedness, up to equivalence.

\begin{definition}
  A simulation $\rho: (\EE, \subEE) \pcato (\FF, \subFF)$ is
  %
  \indexdef{simulation!projective}%
  \indexdef{projective!simulation}%
  %
  \defemph{projective} when there is a single-valued simulation (a function) $\rho'$ such that $\rho' \sim \rho$.
\end{definition}

\begin{exercise}
  Prove that a simulation $\rho : \EE \pcato \FF$ is projective if, and only if,
  there is $t \in \subFF$ such that, for all $x \in \EE$ and $y, z \in \FF$:
  %
  \begin{itemize}
  \item if $y \in \rho[x]$ then $\defined{t\,y}$ and $t\,y \in \rho[x]$,
  \item if $y \in \rho[x]$ and $z \in \rho[x]$ then $t \, y = t \, z$.
  \end{itemize}
  %
  Thus a simulation is projective if each element of $\EE$ has a canonically chosen simulation in~$\FF$.
\end{exercise}


For every simulation $\rho : \EE \pcato \FF$ it is the case that the Boolean values of~$\FF$ can be converted to the simulated Boolean values. Indeed, take any $a \in \rho[\combTrue_\EE]$ and $b \in \rho[\combFalse_\EE]$ and define $e \in \FF'$ to be
$e = \pcalam{x} \combIf_\FF \, x \, a \, b$, so that $e \, \combTrue_\FF \in \rho[\combTrue_\EE]$ and $e \, \combFalse_\FF \in \rho[\combFalse_\EE]$. The converse translation does not come for free.

\begin{definition}
  A simulation $\rho: (\EE, \subEE) \pcato (\FF, \subFF)$ is
  %
  \indexdef{simulation!decidable}%
  \indexdef{decidable!simulation}%
  %
  \defemph{decidable} when there is $d \in \subFF$,
  called the
  %
  \indexdef{decider}%
  %
  \defemph{decider} for~$\rho$, such that, for all $x \in \FF$,
  %
  \begin{align*}
    x \in \rho[\combTrue_\EE] &\lthen d \, x = \combTrue_\FF,
    \\
    x \in \rho[\combFalse_\EE] &\lthen d \, x = \combFalse_\FF.
  \end{align*}
\end{definition}

\begin{exercise}
  \label{exc:simulation-numerals}%
  Say that a simulation $\rho: (\EE, \subEE) \pcato (\FF, \subFF)$ \defemph{preserves numerals}
  when there is $c \in \subFF$ such that, for all $n \in \NN$ and $x \in \FF$,
  %
  \begin{equation*}
    x \in \rho[\overline{n}_\EE] \implies c \, x = \overline{n}_\FF.
  \end{equation*}
  %
  Prove that a simulation is decidable if, and only if, it preserves numerals.
\end{exercise}

We recall several basic results of John Longley's.

\begin{theorem}
  \label{th:simulation-properties2}%
  For $\delta: \EE \pcato \FF$ and $\gamma: \FF \pcato \EE$:
  %
  \begin{enumerate}
  \item
    If $\gamma \circ \delta \preceq \id[\EE]$ then $\delta$ is discrete 
    and $\gamma$ is decidable.
  \item
    If $\gamma \dashv \delta$ then $\gamma$ is projective.
  \end{enumerate}
\end{theorem}

\begin{proof}
  See \cite[Theorem 2.5.3]{Longley:94}.
\end{proof}

\begin{corollary}
  \label{th:simulation-properties}%
  If $\gamma \dashv \delta$ is an adjoint retraction then both~$\delta$
  and~$\gamma$ are discrete and decidable, and~$\gamma$ is projective.
\end{corollary}

\begin{proof}
  Immediate. This is~\cite[Corollary 2.5.4]{Longley:94}.
\end{proof}

\begin{corollary}
  \label{th:simulation-properties-more}%
  If $\EE$ and $\FF$ are equivalent pcas, then the there exist an equivalence
                                %
  \begin{align*}
    \delta &: \EE \pcato \FF,
    &
    \gamma &: \FF \pcato \EE,
  \end{align*}
                                %
  such that $\gamma$ and $\delta$ are single-valued.
\end{corollary}

\begin{proof}
  Both $\delta$ and $\gamma$ are projective by
  \cref{th:simulation-properties2}.
\end{proof}

\subsection[\texorpdfstring{Decidable simulations and $\klone$}{Decidable simulations and K1}]
{Decidable simulations and $\klone$}
\label{sec:decidable-simulations}

Decidable simulations are the kind of simulations that arise in computability theory.
We investigate them a bit, especially in relation to the first Kleene algebra~$\klone$.

Turing machines, embodied as Kleene's first algebra~$\klone$, are distinguished by a universal property.

\begin{theorem}
  Up to equivalence, the first Kleene algebra~$\klone$ is initial in the category of pcas and decidable simulations.
\end{theorem}

\begin{proof}
  We sketch the proof from \cite[Theorem 2.4.18]{Longley:94}. Given any pca~$\AA$, define $\kappa : \klone \pcato \AA$ by $\kappa[n] = \set{\numeral{n}_{\AA}}$. Because every partial computable function $\NN \times \NN \parto \NN$ can be represented in~$\AA$, there is $r \in \AA$ such that, for all $k, m, n \in \NN$,
  %
  \begin{equation*}
    r \, \numeral{k} \, \numeral{m} = \numeral{n} \iff \pr{k}{m} = n.
  \end{equation*}
  %
  Such an element~$r$ realizes~$\kappa$. Furthermore, $\kappa$ is decidable because it maps numbers to numerals.

  Suppose $\mu : \klone \pcato \AA$ is another decidable simulation. Because $\mu$ preserves numerals there exists $f \in \AA$ such that if $a \in \mu[n]$ then $f \, a = \numeral{n} \in \kappa[n]$, therefore $\mu \preceq \kappa$. The relation $\kappa \preceq \mu$ holds by the next exercise, therefore $\kappa \sim \mu$.
\end{proof}

\begin{exercise}
  Verify that for any $\rho : \EE \pcato \FF$ there is $q \in \FF$ such that $q \, \overline{n}_{\FF} \in \rho[\overline{n}_{\EE}]$ for all $n \in \NN$.
\end{exercise}

Recall that a \defemph{Turing reduction} of $A \subseteq \NN$ to $B \subseteq \NN$, written $A \leq_T B$ is a $B$-oracle Turing machine~$M$ which computes the characteristic function of~$A$.

\begin{theorem}
  Suppose $A, B \subseteq \NN$. Then $A \leq_T B$ if, and only if, there is a decidable simulation $\klone^A \pcato \klone^B$.
\end{theorem}

\begin{proof}
  This is \cite[Proposition 3.1.6]{Longley:94}.
\end{proof}

The following definition and exercise verify that having decidable simulations between~$\EE$ and~$\FF$ implies that they both compute the same number-theoretic functions, which is sometimes taken to be a notion of equivalence of computational models.

\begin{definition}
  Say that a function $f : \NN \to \NN$ is \defemph{realizable} in a pca~$\AA$ when there exists $r \in \AA$ such that $\defined{a \, \numeral{n}}$ and $a \, \numeral{n} = \numeral{f(n)}$, for all $n \in \NN$.

  Pcas $\EE$ and $\FF$ are \defemph{Turing-equivalent} when they realize the same maps $\NN \to \NN$.
  A pca is \defemph{Turing-complete} when it is Turing-equivalent to~$\klone$.
\end{definition}

\begin{exercise}
  Suppose that
  %
  \begin{align*}
    \delta &: \EE \pcato \FF
    &
      \gamma &: \FF \pcato \EE
  \end{align*}
  %
  are decidable simulations. Show that~$\EE$ and~$\FF$ are Turing-equivalent.
\end{exercise}

Consider again decidable simulations
%
\begin{align*}
  \delta &: \EE \pcato \klone
  &
  \gamma &: \klone \pcato \EE.
\end{align*}
%
Because $\klone$ is initial, $\gamma$ is equivalent to $n \mapsto \numeral{n}$, so we might as well assume that $\gamma[n] = \set{\numeral{n}}$. Initiality also implies that $\delta \circ \gamma \sim \id[\klone]$.

Think of $n \in \delta[x]$ as the ``source code'' of~$x \in \EE$.
%
A translation $t \in \EE$ witnessing $\gamma \circ \delta \preceq \id[\EE]$ is a \defemph{self-interpreter} for~$\EE$. Indeed, given $x \in \EE$ and $n \in \delta[x]$ we have $t \, \numeral{n} = x$, which says that $t$ evaluates the source code~$n$ to the value~$x$ represented by the source code.
%
Therefore, an adjoint retraction $\gamma \dashv \delta$ from $\EE$ onto~$\klone$ encompasses two features of~$\EE$, a self-interpreter and Turing-completeness.

\subsubsection{An adjoint retraction from $\Lambda$ to $\klone$}
\label{sec:adjo-retr-from}

We construct an adjoint retraction from the pca $\Lambda$ of the closed terms of the untyped $\lambda$-calculus, and first Kleene algebra~$\klone$.

Define $\delta : \klone \pcato \Lambda$ to be the simulation $\delta[n] = \set{\numeral{n}}$ which encodes numbers as Curry numerals.
%
It is a simulation because every partial computable map is $\lambda$-definable, and therefore so is Kleene application.

In the opposite direction, let $\gamma : \Lambda \pcato \klone$ be the total relation (remember that $\Lambda$ is the set of closed terms quotiented by $\beta$-reduction),
%
\begin{equation*}
  \gamma[t] = \set{ \code{t'} \such t' \in \Lambda \land t =_\beta t' }.
\end{equation*}
%
That is, an equivalence class of a closed terms is simulated by the codes of its members.
The simulation is realized because there is a computable map~$f : \NN \times \NN \parto \NN$ satisfying $f(\code{t}, \code{u}) = \code{t \, u}$ for all $t, u \in \Lambda$.

Verifying $\delta \circ \gamma \preceq \id[\Lambda]$ is a simple matter of programming a self-interpreter for the untyped $\lambda$-calculus. From a conceptual point of view it is clear that this can be done: the syntax of a term~$t$ can be discerned from the numeral $\numeral{\code{t}}$, so one just has to recursively traverse syntax tree of~$t$ and interpret it into $\lambda$-calculus.

\begin{exercise}
  Why is it \emph{not} the case that $\id[\Lambda] \preceq \delta \circ \gamma$?
\end{exercise}

\subsubsection{An adjoint retraction from $\comp{\Scott}$ to $\klone$}
\label{ex:pcamorphism_K1_RE}%

\index{retraction!between P and N@{between~$\comp{\Scott}$ and~$\klone$}}%
%
Here is one more example, an adjoint retraction from the computable graph model~$\comp{\Scott}$ and the first Kleene algebra~\cite[Proposition 3.3.7]{Longley:94}.
%
In one direction we define $\delta: \klone \pcato \comp{\Scott}$ by
%
\begin{equation*}
  \delta[n] = \set{\set{n}}.
\end{equation*}
%
Careful with the nested singletons: the number~$n$ is simulated by the singleton $\set{n}$.

\begin{exercise}
  Above we used singletons $\set{n}$ as numerals, but in~\eqref{eq:curry-numeral} we defined the Curry numerals $\overline{n}$. Verify that in $\comp{\Scott}$ we can translate between these, i.e., that there are computable enumeration operators $f : \comp{\Scott} \to \comp{\Scott}$ and $g : \comp{\Scott} \to \comp{\Scott}$ such that $f(\set{n}) = \overline{n}_{\comp{\Scott}}$ and $g(\overline{n}_{\comp{\Scott}}) = \set{n}$, for all $n \in \NN$.
\end{exercise}

In the other direction we define $\gamma: \comp{\Scott} \pcato \klone$ by taking
% 
\begin{equation*}
  \gamma[A] = \set{n \in \NN \such \im{\xpr_n} = A}
\end{equation*}
%
to be the index set\sidenote{In computability theory, the \defemph{index set} of a set $A$ is the set of all numbers (the indices) that encode elements of~$A$.} of~$A$, i.e., the codes of partial computable maps whose image is~$A$.

\begin{exercise}
  Verify that $\delta$ and $\gamma$ are simulations.
\end{exercise}

To establish $\delta \circ \gamma \preceq \id[\comp{\Scott}]$, observe that
%
\begin{equation*}
  S = \set{ \code{\pair{\code{\set{m}}, n}} \such \some{k \in \NN} \pr{m}{k} = n }
\end{equation*}
%
is computably enumerable. The computable enumeration operator $\Lambda(S) : \comp{\Scott} \to \comp{\Scott}$, where $\Lambda$ is as in \eqref{eq:scott-section-retraction} is then a translation from $\delta \circ \gamma$ to $\id[\comp{\Scott}]$.

\begin{exercise}
  Why is it \emph{not} the case that $\id[\comp{\Scott}] \preceq \delta \circ \gamma$?
\end{exercise}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection[\texorpdfstring{An adjoint retraction from $(\Scott, \comp{\Scott})$ to $(\Baire, \comp{\Baire})$}{An adjoint retraction from P to B}]
{An adjoint retraction from $(\Scott, \comp{\Scott})$ to $(\Baire, \comp{\Baire})$}
\label{sec:retraction-PP-BB}%

\index{retraction!between P and B@{between~$(\Scott, \comp{\Scott})$ and~$(\Baire, \comp{\Baire})$}}%
%

To give at least one example of simulations between pcas with sub-pcas, we review the adjoint retraction between the graph model and Kleene's second algebra, which was first given by Peter Lietz~\cite{Lietz:04}.

The map $\iota: \Baire \to \Scott$, defined by
                                %
\begin{equation*}
  \iota \, \alpha =
  \set{ \code{a} \such
    a \in \NN^{*} \land a \sqsubseteq \alpha
    }
\end{equation*}
%
represents a sequence $\alpha$ with the set (of codes) of its initial segments. It restricts to a map $\comp{\Baire} \to \comp{\Scott}$. Let us show that it is a simulation.

In \cref{sec:type-2}  we defined the application $\alpha \cdot_{\Baire} \beta$ in $\Baire$ by a lookup procedure, by which every initial segment of $\alpha \cdot_{\Baire} \beta$ is determined by sufficiently long initial segments of~$\alpha$ and~$\beta$. Thus the relation $R \subseteq \NN^{*} \times \NN^{*} \times \NN^{*}$ defined by
%
\begin{multline*}
  (a, b, c) \in R \iff \\
  \all{\alpha, \beta, \gamma \in \Baire}
  \defined{(\alpha \cdot_{\Baire} \beta)} \land
  a \sqsubseteq \alpha \land
  b \sqsubseteq \beta
  \lthen
  c \sqsubseteq \alpha \cdot_{\Baire} \beta
\end{multline*}
%
is computable. The enumeration operator $p : \Scott \times \Scott \to \Scott$, defined by
% 
\begin{equation*}
  p (A, B) =
  \set{ \code{c} \such
        \some{a, b \in \NN^{*}}
          \code{a} \in A \land \code{b} \in B \land (a, b, c) \in R },
\end{equation*}
% 
is computable and is (the curried form of) a realizer for~$\iota$.

Let $\delta: \Scott \pcato \Baire$ be the simulation defined by
%
\begin{equation*}
  \delta[A] =
  \set{ \alpha \in \Baire \such
        A = \set{n \in \NN \such \some{k \in \NN} \alpha\,k = n + 1}
  }.
\end{equation*}
%
In words, $\alpha$ is a $\delta$-simulation of~$A$ when it
enumerates~$A$, where the trick with adding~$1$ to~$n$ in the above definition makes it possible to enumerate the empty set. Clearly, if $\alpha \in \comp{\Baire}$
then~$A \in \comp{\Scott}$. In order for~$\delta$ to be a simulation, it suffices to find a partial computable map $f : \Baire \times \Baire \parto \Baire$ such that,
for all $A, B \in \Scott$,
% 
\begin{equation*}
  \alpha \in \delta[A] \land
  \beta \in \delta[B]
  \lthen
  f (\alpha, \beta) \in \delta[A \cdot_{\Scott} B].
\end{equation*}
% 
To determine $f (\alpha, \beta) \, \code{(m, n)}$, we look for $j < m$ such that $\alpha \, j = 1 + \code{(\code{C}, n)}$ and $C \wayb A$. If there is one, we set $f (\alpha, \beta) \, \code{(m, n)} = n + 1$, otherwise we set it to~$0$.
Clearly, this is an effective procedure. If we compare the definition of~$f$ to the definition of application in~$\Scott$, we see that they match.

Let us show that $\iota \dashv \delta$ is an adjoint retraction.
%
Suppose $\alpha \in \Baire$ and $\beta \in \delta[\iota(\alpha)]$.
%
We can computably reconstruct~$\alpha$ from~$\beta$, because $\beta$ enumerates the initial
segments of~$\alpha$. This shows that $\delta \circ \iota \preceq \id[\Baire]$. Also, given $\alpha$ we can easily
construct a sequence~$\beta$ which enumerates the initial segments of~$\alpha$, therefore
$\id[\Baire] \preceq \delta \circ \iota$, and we conclude that $\delta \circ \iota \sim \id[\Baire]$.

To see that $\iota \circ \delta \preceq \id[\Scott]$, consider $A, B \in \Scott$ and $\alpha \in \Baire$ such that $\alpha in \delta[A]$ and $B = \iota(\alpha)$. The sequence~$\alpha$ enumerates~$A$, and $B$ consists of the initial segments of~$\alpha$. Hence, we can effectively reconstruct $A$ from $B$, by
%
\begin{equation*}
  m \in A
  \iff
  \some{n \in B} n = 1 + \code{a} \land \some{i < \T{a}} m = a_i.
\end{equation*}


\subsubsection{Equivalence of Reflexive Domains}
\label{sec:equivalence_reflexive_domains}%

Consider reflexive domains
%
\begin{equation*}
  \xymatrix{
    **[l]{\mathcal{C}(D, D)}
    \ar@<+0.25em>[r]^{\Gamma_D}
    &
    {D}
    \ar@<+0.25em>[l]^{\Lambda_D}
  }
  \qquad\qquad
  \xymatrix{
    **[l]{\mathcal{C}(E, E)}
    \ar@<+0.25em>[r]^{\Gamma_E}
    &
    {D}
    \ar@<+0.25em>[l]^{\Lambda_E}
  }
\end{equation*}
%
which are also retracts of each other,
%
\begin{equation*}
  \xymatrix{
    {D}
    \ar@<+0.25em>[r]^{s_D}
    &
    {E}
    \ar@<+0.25em>[l]^{r_D}
  }
  \qquad\qquad
  \xymatrix{
    {E}
    \ar@<+0.25em>[r]^{s_E}
    &
    {D}
    \ar@<+0.25em>[l]^{r_E}
  } 
\end{equation*}
%
so $r_D \circ s_D = \id[D]$ and $r_E \circ s_E = \id[E]$. Then $D$ and $E$ are equivalent as pcas.

\begin{exercise}
  Verify the claim by constructing an equivalence $D \sim E$ from the given section-retraction pairs.
\end{exercise}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "notes-on-realizability"
%%% End:
